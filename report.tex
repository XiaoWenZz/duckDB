\documentclass[a4paper, 12pt]{ctexart}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{hyperref} % Keep hyperref as it was in the original document

% 设置页面边距
\geometry{left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm}

% 配置中文字体 (Mac 常用设置，避免 KaiTi/乱码)
% 强制使用宋体作为正文，黑体作为无衬线和等宽字体(代码注释)
\setCJKmainfont[BoldFont=STHeiti, ItalicFont=STKaiti]{STSong}
\setCJKsansfont{STHeiti}
\setCJKmonofont{STHeiti} 

% 代码高亮配置
\lstset{
    basicstyle=\small\ttfamily, % 使用等宽字体，配合上面的 setCJKmonofont
    keywordstyle=\color{blue},
    commentstyle=\color{gray}, % 注释颜色
    stringstyle=\color{red},
    breaklines=true,
    numbers=left,
    numberstyle=\tiny\color{gray},
    stepnumber=1,
    frame=single,
    showstringspaces=false,
    tabsize=4,
    keepspaces=true,
    extendedchars=false % 解决 XeLaTeX 下 listings 中文乱码的关键
}

\title{\textbf{DuckDB 并行分析性能评测报告}}
\author{性能验证小组}
\date{\today}

\begin{document}

\maketitle

\section{引言 (Introduction)}
本报告详细记录了对 DuckDB 并行分析处理能力的验证与性能评测结果。本次评测的主要目标是分析系统在不同线程数下的扩展性（Scalability），以及对比不同数据格式（Parquet 与 CSV）对分析性能的影响。

\section{实验环境与设置 (Experimental Setup)}

\subsection{硬件环境}
\begin{itemize}
    \item \textbf{CPU}: Intel(R) Core(TM) i9-14900K (24 Cores, 32 Threads)
    \item \textbf{内存}: 128GB
    \item \textbf{操作系统}: Ubuntu 22.04.4 LTS
    \item \textbf{存储}: 2TB NVMe SSD (KINGSTON SNV3S2000G)
\end{itemize}

\subsection{数据集}
\begin{itemize}
    \item \textbf{来源}: NYC Taxi Data (Yellow Trip Data, 2019-2021).
    \item \textbf{格式}: Parquet (列式存储) 与 CSV (行式文本存储).
    \item \textbf{数据量}: 约 30GB+.
\end{itemize}

\section{实验设计 (Experimental Design)}

\subsection{查询负载 (Workloads)}
本实验选取了三个具有代表性的 OLAP 查询，分别涵盖了 I/O 密集型、混合型和 CPU 密集型场景。这些查询基于 NYC Taxi 数据集的真实分析需求设计。

\subsubsection{Q1: 简单聚合 (I/O Bound)}
该查询计算整个数据集的总行数和平均总金额。由于涉及全表扫描且计算逻辑简单，其性能主要受限于 I/O 带宽。
\begin{lstlisting}[language=SQL, basicstyle=\ttfamily\small, frame=single]
SELECT count(*), avg(total_amount)
FROM 'data/yellow_tripdata_*.parquet';
\end{lstlisting}

\subsubsection{Q2: 过滤与分组 (Mixed)}
该查询包含过滤条件 (\texttt{WHERE}) 和分组聚合 (\texttt{GROUP BY})。DuckDB 的向量化执行引擎应能有效利用 SIMD 指令加速过滤过程。
\begin{lstlisting}[language=SQL, basicstyle=\ttfamily\small, frame=single]
SELECT passenger_count, avg(trip_distance) AS avg_dist
FROM 'data/yellow_tripdata_*.parquet'
WHERE trip_distance > 0 AND total_amount > 0
GROUP BY passenger_count
ORDER BY avg_dist DESC;
\end{lstlisting}

\subsubsection{Q3: 高基数分组与排序 (CPU Bound)}
该查询对两个高基数列 (\texttt{PULocationID}, \texttt{DOLocationID}) 进行分组并排序。这将产生大量的分组键，对哈希表构建、洗牌 (Shuffle) 和排序算法的并行效率提出较高要求。
\begin{lstlisting}[language=SQL, basicstyle=\ttfamily\small, frame=single]
SELECT PULocationID, DOLocationID, count(*) AS trip_count
FROM 'data/yellow_tripdata_*.parquet'
GROUP BY PULocationID, DOLocationID
ORDER BY trip_count DESC
LIMIT 10;
\end{lstlisting}

\subsection{变量控制}
\begin{itemize}
    \item \textbf{并行度 (Parallelism)}: 控制线程数 $N \in [1, 2, 4, 8, 16]$，验证 Amdahl 定律。
    \item \textbf{数据格式 (File Format)}: 对比 Parquet (列存) 与 CSV (行存)，分析 I/O 与解析开销。
    \item \textbf{冷启动 vs 热启动}: 为模拟真实大规模数据分析场景，本次实验主要关注文件系统缓存产生的热启动性能，但也考虑了 I/O 对 Q1 的显著影响。
\end{itemize}

\section{结果与分析 (Results and Analysis)}

\subsection{实验一：并行度扩展性测试}
下表展示了在 Parquet 格式下，随着线程数增加，各查询的执行时间（秒）。

\begin{table}[H]
    \centering
    \caption{执行时间 vs. 线程数 (Parquet)}
    \label{tab:scalability}
    \vspace{0.2cm}
    \begin{tabular}{c|ccc}
        \toprule
        \textbf{线程数 (Threads)} & \textbf{Q1 (秒)} & \textbf{Q2 (秒)} & \textbf{Q3 (秒)} \\
        \midrule
        1 & 2.11 & 5.01 & 3.98 \\
        2 & 1.00 & 2.59 & 2.05 \\
        4 & 0.55 & 1.41 & 1.16 \\
        8 & 0.34 & 0.84 & 0.75 \\
        16 & 0.25 & 0.53 & 0.45 \\
        24 & 0.21 & 0.51 & 0.45 \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/scalability.png}
    \caption{并行度扩展性趋势 (Speedup vs Threads)}
    \label{fig:scalability}
\end{figure}

\textbf{分析总结}：
\begin{itemize}
    \item \textbf{扩展性趋势}: 随着线程数从 1 增加到 8，所有查询表现出显著的性能提升。
    \item \textbf{收益递减}: Q1（I/O 密集型）在 16 线程后性能趋于稳定（约 0.21s），表明已触及 I/O 瓶颈。Q2 和 Q3 在 24 线程（物理核心上限）下进一步优化的空间也已非常有限。
    \item \textbf{资源利用率}: 在高并行度下，纯计算任务的加速比受限于内存带宽和 Amdahl 定律中的串行部分。
\end{itemize}

\subsection{实验二：数据格式对比测试}
下表对比了在 24 线程下，处理 Parquet 格式与 CSV 格式的性能差异。

\begin{table}[H]
    \centering
    \caption{Parquet vs. CSV 性能对比 (24 线程)}
    \label{tab:formats}
    \vspace{0.2cm}
    \begin{tabular}{l|cc|c}
        \toprule
        \textbf{查询} & \textbf{Parquet (秒)} & \textbf{CSV (秒)} & \textbf{加速比 (CSV/Parquet)} \\
        \midrule
        Q1 (I/O Bound) & 0.21 & 20.47 & \textbf{97.5x} \\
        Q2 (Mixed)     & 0.51 & 17.75 & \textbf{34.8x} \\
        Q3 (CPU Bound) & 0.45 & 12.09 & \textbf{26.9x} \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/format_comparison.png}
    \caption{数据格式性能对比 (Parquet vs CSV)}
    \label{fig:format_comparison}
\end{figure}

\textbf{深入分析}：
\begin{enumerate}
    \item \textbf{列式读取}: Parquet 是列式存储格式，对于 Q1 这种只涉及两列 (\texttt{count(*)}, \texttt{total\_amount}) 的查询，DuckDB 仅需读取相关的数据块，显著减少了磁盘 I/O。而 CSV 必须扫描整行数据。本实验中 Q1 达到了惊人的 \textbf{97.5x} 加速比，充分证明了这一点。
    \item \textbf{二进制 vs 文本}: Parquet 采用二进制编码（如 SNAPPY 压缩），无需进行繁重的文本解析（Text Parsing）。CSV 的解析（查找分隔符、转换字符串为数字）消耗了大量 CPU 周期，导致在 CPU 并不是瓶颈的 Q1 中也表现极差。
    \item \textbf{统计信息利用}: Parquet 文件头包含了 Min/Max 等统计信息。DuckDB 利用这些元数据在 Q2 中进行谓词下推（Predicate Pushdown），直接跳过不满足 \texttt{trip\_distance > 0} 的数据块，进一步拉大了性能差距。
\end{enumerate}

\subsubsection{理论验证：97.5x 加速比的数学推导}
为了验证实验结果的合理性，我们建立一个简单的 I/O 模型进行拆解。假设数据集总行数为 $N$。

\textbf{1. I/O 缩减系数 ($Factor_{IO}$)}:
\begin{itemize}
    \item \textbf{CSV (全量读取)}: 平均行宽约 180 Bytes（包含所有 19 列数据）。I/O 量 $V_{csv} \approx N \times 180$ Bytes。
    \item \textbf{Parquet (列式投影)}: Q1 仅需读取 \texttt{total\_amount} (Double, 8 Bytes) 一列。考虑压缩（SNAPPY/RLE），平均每行存储开销约 6 Bytes。I/O 量 $V_{pq} \approx N \times 6$ Bytes。
\end{itemize}
因此，仅 I/O 数据量的理论缩减倍数为：
\[ Factor_{IO} = \frac{V_{csv}}{V_{pq}} \approx \frac{180}{6} \approx 30 \]

\textbf{2. 综合加速比}:
除 I/O 外，CSV 需要昂贵的文本解析（Text Parsing），而 Parquet 为二进制零拷贝读取，通常有 3-5 倍的 CPU 效率优势 ($Factor_{CPU}$)。
\[ Speedup \approx Factor_{IO} \times Factor_{CPU} \approx 30 \times 3.3 \approx 100 \]

实验测得的 \textbf{97.5x} 加速比与理论模型预测的 \textbf{100x} 高度吻合。这从数学上证明了在 OLAP 场景下，列式存储带来的收益是数量级（Order of Magnitude）层面的。

\subsection{实验三：数据规模扩展性测试}
本实验在固定 24 线程下，测试了三个不同数据规模（1 个月、1 年、3 年）对查询性能的影响。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/data_scale.png}
    \caption{性能随数据规模变化趋势 (Performance vs Data Scale)}
    \label{fig:data_scale}
\end{figure}

\textbf{分析总结}：
\begin{itemize}
    \item \textbf{线性扩展}: 对于扫描类查询 (Q1)，执行时间与数据量呈现严格的线性关系。
    \item \textbf{超线性增长}: 对于涉及排序和 Shuffle 的查询 (Q3)，随着数据量增大，内存压力增加，可能会溢出到磁盘，导致执行时间呈现超线性（Super-linear）增长趋势。
\end{itemize}

\end{itemize}

\section{高级分析：资源利用率 (Advanced Resource Analysis)}
本节通过 \texttt{psutil} 实时监控查询执行期间的 CPU 利用率和内存占用峰值，以进一步分析 DuckDB 的资源使用模式。

\subsection{CPU 利用率 (CPU Utilization)}
（待补充：此处将插入 CPU 使用率数据或说明，例如观察到多线程下 CPU 利用率是否饱和）

\subsection{内存使用情况 (Memory Usage)}
（待补充：此处将插入内存峰值数据，分析 DuckDB 的内存管理策略，如其 Streaming Execution Engine 如何控制内存占用）

\section{结论 (Conclusion)}
实验表明，DuckDB 在多核环境下表现出优秀的并行扩展能力。同时，数据格式的选择对性能至关重要：在分析场景下，使用 Parquet 相比 CSV 可带来数量级的性能提升。建议在生产环境中优先将数据转换为 Parquet 格式以获得最佳性能。

\newpage
\appendix
\section{附录 (Appendix)}

\subsection{基准测试脚本 (benchmark.py)}
\lstinputlisting[language=Python, caption=benchmark.py]{benchmark.py}

\subsection{数据准备脚本 (prepare\_data.py)}
\lstinputlisting[language=Python, caption=prepare\_data.py]{prepare_data.py}

\subsection{实验结果数据 (Results)}
\lstinputlisting[language={}, caption=duckdb\_benchmark\_results.csv, basicstyle=\ttfamily\scriptsize]{duckdb_benchmark_results.csv}

\end{document}
