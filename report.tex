\documentclass[a4paper, 12pt]{ctexart}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{hyperref} % Keep hyperref as it was in the original document

% 设置页面边距
\geometry{left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm}

% 配置中文字体 (Mac 常用设置，避免 KaiTi/乱码)
% 强制使用宋体作为正文，黑体作为无衬线和等宽字体(代码注释)
\setCJKmainfont[BoldFont=STHeiti, ItalicFont=STKaiti]{STSong}
\setCJKsansfont{STHeiti}
\setCJKmonofont{STHeiti} 

% 代码高亮配置
\lstset{
    basicstyle=\small\ttfamily, % 使用等宽字体，配合上面的 setCJKmonofont
    keywordstyle=\color{blue},
    commentstyle=\color{gray}, % 注释颜色
    stringstyle=\color{red},
    breaklines=true,
    numbers=left,
    numberstyle=\tiny\color{gray},
    stepnumber=1,
    frame=single,
    showstringspaces=false,
    tabsize=4,
    keepspaces=true,
    extendedchars=false % 解决 XeLaTeX 下 listings 中文乱码的关键
}

\title{\textbf{DuckDB 并行分析性能评测报告}}
\author{郑腾雄 51285902039}
\date{\today}

\begin{document}

\maketitle

\section{引言 (Introduction)}
本报告详细记录了对 DuckDB 并行分析处理能力的验证与性能评测结果。本次评测的主要目标是分析系统在不同线程数下的扩展性（Scalability），以及对比不同数据格式（Parquet 与 CSV）对分析性能的影响。

\section{实验环境与设置 (Experimental Setup)}

\subsection{硬件环境}
\begin{itemize}
    \item \textbf{CPU}: Intel(R) Core(TM) i9-14900K (24 Cores, 32 Threads)
    \item \textbf{内存}: 128GB
    \item \textbf{操作系统}: Ubuntu 22.04.4 LTS
    \item \textbf{存储}: 2TB NVMe SSD (KINGSTON SNV3S2000G)
\end{itemize}

\subsection{数据集}
\begin{itemize}
    \item \textbf{来源}: NYC Taxi Data (Yellow Trip Data, 2019-2021).
    \item \textbf{格式}: Parquet (列式存储) 与 CSV (行式文本存储).
    \item \textbf{数据量}: 约 30GB+.
\end{itemize}

\section{实验设计 (Experimental Design)}

\subsection{查询负载 (Workloads)}
本实验选取了三个具有代表性的 OLAP 查询，分别涵盖了 I/O 密集型、混合型和 CPU 密集型场景。这些查询基于 NYC Taxi 数据集的真实分析需求设计。

\subsubsection{Q1: 简单聚合 (I/O Bound)}
该查询计算整个数据集的总行数和平均总金额。由于涉及全表扫描且计算逻辑简单，其性能主要受限于 I/O 带宽。
\begin{lstlisting}[language=SQL, basicstyle=\ttfamily\small, frame=single]
SELECT count(*), avg(total_amount)
FROM 'data/yellow_tripdata_*.parquet';
\end{lstlisting}

\subsubsection{Q2: 过滤与分组 (Mixed)}
该查询包含过滤条件 (\texttt{WHERE}) 和分组聚合 (\texttt{GROUP BY})。DuckDB 的向量化执行引擎应能有效利用 SIMD 指令加速过滤过程。
\begin{lstlisting}[language=SQL, basicstyle=\ttfamily\small, frame=single]
SELECT passenger_count, avg(trip_distance) AS avg_dist
FROM 'data/yellow_tripdata_*.parquet'
WHERE trip_distance > 0 AND total_amount > 0
GROUP BY passenger_count
ORDER BY avg_dist DESC;
\end{lstlisting}

\subsubsection{Q3: 高基数分组与排序 (CPU Bound)}
该查询对两个高基数列 (\texttt{PULocationID}, \texttt{DOLocationID}) 进行分组并排序。这将产生大量的分组键，对哈希表构建、洗牌 (Shuffle) 和排序算法的并行效率提出较高要求。
\begin{lstlisting}[language=SQL, basicstyle=\ttfamily\small, frame=single]
SELECT PULocationID, DOLocationID, count(*) AS trip_count
FROM 'data/yellow_tripdata_*.parquet'
GROUP BY PULocationID, DOLocationID
ORDER BY trip_count DESC
LIMIT 10;
\end{lstlisting}

\subsection{变量控制}
\begin{itemize}
    \item \textbf{并行度 (Parallelism)}: 控制线程数 $N \in [1, 2, 4, 8, 16]$，验证 Amdahl 定律。
    \item \textbf{数据格式 (File Format)}: 对比 Parquet (列存) 与 CSV (行存)，分析 I/O 与解析开销。
    \item \textbf{冷启动 (Cold Start)}: 为了排除操作系统页缓存（Page Cache）的干扰，每次实验运行前均强制清理系统缓存 (\texttt{drop\_caches})，确保测量真实的磁盘 I/O 性能。
\end{itemize}

\section{结果与分析 (Results and Analysis)}

\subsection{实验一：并行度扩展性测试}
下表展示了在 Parquet 格式下，随着线程数增加，各查询的执行时间（秒）。

\begin{table}[H]
    \centering
    \caption{执行时间 vs. 线程数 (Parquet)}
    \label{tab:scalability}
    \vspace{0.2cm}
    \begin{tabular}{c|ccc}
        \toprule
        \textbf{线程数 (Threads)} & \textbf{Q1 (秒)} & \textbf{Q2 (秒)} & \textbf{Q3 (秒)} \\
        \midrule
        1 & 1.20 & 2.95 & 2.08 \\
        2 & 0.62 & 1.50 & 1.10 \\
        4 & 0.38 & 0.80 & 0.64 \\
        8 & 0.30 & 0.54 & 0.44 \\
        16 & 0.22 & 0.40 & 0.34 \\
        24 & 0.22 & 0.42 & 0.34 \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/scalability.png}
    \caption{并行度扩展性趋势 (Speedup vs Threads)}
    \label{fig:scalability}
\end{figure}

\textbf{分析总结}：
\begin{itemize}
    \item \textbf{扩展性趋势}: 随着线程数从 1 增加到 8，所有查询表现出显著的性能提升。
    \item \textbf{收益递减}: Q1（I/O 密集型）在 16 线程后性能趋于稳定（约 0.20s），表明已触及 I/O 瓶颈。Q2 和 Q3 在 24 线程（物理核心上限）下进一步优化的空间也已非常有限。
    \item \textbf{资源利用率}: 在高并行度下，纯计算任务的加速比受限于内存带宽和 Amdahl 定律中的串行部分。
\end{itemize}

\subsection{实验二：数据格式对比测试}
下表对比了在 24 线程下，处理 Parquet 格式与 CSV 格式的性能差异。

\begin{table}[H]
    \centering
    \caption{Parquet vs. CSV 性能对比 (24 线程)}
    \label{tab:formats}
    \vspace{0.2cm}
    \begin{tabular}{l|cc|c}
        \toprule
        \textbf{查询} & \textbf{Parquet (秒)} & \textbf{CSV (秒)} & \textbf{加速比 (CSV/Parquet)} \\
        \midrule
        Q1 (I/O Bound) & 0.22 & 7.72 & \textbf{34.9x} \\
        Q2 (Mixed)     & 0.42 & 7.52 & \textbf{17.8x} \\
        Q3 (CPU Bound) & 0.34 & 7.78 & \textbf{22.8x} \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/format_comparison.png}
    \caption{数据格式性能对比 (Parquet vs CSV)}
    \label{fig:format_comparison}
\end{figure}

\textbf{深入分析}：
\begin{enumerate}
    \item \textbf{列式读取}: Parquet 为列式存储，Q1 仅涉及两列 (\texttt{count(*)}, \texttt{total\_amount})，DuckDB 仅需按需读取数据块，有效降低了 I/O 数据量。相比之下，CSV 需进行全行扫描。Q1 测得 \textbf{34.9x} 加速比验证了这一点。
    \item \textbf{解析开销}: Parquet 采用二进制编码（如 SNAPPY），避免了复杂的文本解析。CSV 解析（处理分隔符、类型转换）占用了显著的 CPU 资源，导致其在非计算密集型的 Q1 中性能也明显下降。
    \item \textbf{谓词下推}: Parquet 文件头包含统计元数据（Min/Max）。DuckDB 在 Q2 中利用此特性进行谓词下推（Predicate Pushdown），跳过不符合 \texttt{trip\_distance > 0} 的数据块，进一步扩大了性能差异。 \end{enumerate}

\subsubsection{理论验证：加速比的数学推导}
为了验证实验结果的合理性，我们建立一个简单的 I/O 模型进行拆解。假设数据集总行数为 $N$。

\textbf{1. I/O 缩减系数 ($Factor_{IO}$)}:
\begin{itemize}
    \item \textbf{CSV (全量读取)}: 平均行宽约 180 Bytes（包含所有 19 列数据）。I/O 量 $V_{csv} \approx N \times 180$ Bytes。
    \item \textbf{Parquet (列式投影)}: Q1 仅需读取 \texttt{total\_amount} (Double, 8 Bytes) 一列。考虑压缩（SNAPPY/RLE），平均每行存储开销约 6 Bytes。I/O 量 $V_{pq} \approx N \times 6$ Bytes。
\end{itemize}
因此，仅 I/O 数据量的理论缩减倍数为：
\[ Factor_{IO} = \frac{V_{csv}}{V_{pq}} \approx \frac{180}{6} \approx 30 \]

    \textbf{2. 综合加速比}:
    除 I/O 差异外，CSV 涉及昂贵的文本解析，而 Parquet 仅需二进制读取。设定解析带来的额外 CPU 效率提升系数为 $Factor_{CPU}$ (约为 1.2 \textasciitilde 2.0)。
    \[ Speedup \approx Factor_{IO} \times Factor_{CPU} \approx 30 \times 1.2 \approx 36 \]
    
    实验测得的 \textbf{34.9x} 加速比与理论估算区间基本一致，验证了列式存储在降低数据扫描量和解析开销方面的双重优势。

\subsection{实验三：数据规模扩展性测试}
本实验在固定 24 线程下，测试了三个不同数据规模（1 个月、1 年、3 年）对查询性能的影响。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/data_scale.png}
    \caption{性能随数据规模变化趋势 (Performance vs Data Scale)}
    \label{fig:data_scale}
\end{figure}

\textbf{分析总结}：
\begin{itemize}
    \item \textbf{低延迟响应}: 在 3 年数据规模下，查询响应时间保持在毫秒级（0.2s \textasciitilde 0.4s），体现了 DuckDB 列式引擎在处理简单聚合查询时的高效性。
    \item \textbf{开销主导模型}: 3 年数据的耗时未随数据量线性增长（未达到 1 个月的 36 倍）。这是由于在亚秒级查询中，固定开销（SQL 解析、规划、线程启动）在总耗时中占比较高，掩盖了数据扫描的时间差异。这表明当前负载下磁盘扫描尚未成为主要瓶颈。
\end{itemize}



\section{高级分析：资源利用率 (Advanced Resource Analysis)}
本节通过 \texttt{psutil} 实时监控查询执行期间的 CPU 利用率和内存占用峰值，以进一步分析 DuckDB 的资源使用模式。

\subsection{并行资源扩展性 (Resource Scalability)}
图 \ref{fig:resource_scalability} 展示了在 Parquet 格式下，CPU 利用率和内存占用随线程数的变化趋势。
\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/resource_scalability.png}
    \caption{CPU 利用率与内存占用随线程数变化 (CPU \& Memory vs Threads)}
    \label{fig:resource_scalability}
\end{figure}

实验数据显示：
\begin{itemize}
    \item \textbf{CPU 利用率}: 随线程数增加，CPU 利用率呈上升趋势。在 24 线程下，Q2 和 Q3 的利用率达到 \textbf{1138\%\textasciitilde1192\%}，表明系统能有效利用多核资源。Q1 受 I/O 限制，利用率相对较低 (\textbf{964\%})。
    \item \textbf{内存占用}: 内存使用量随线程数增加轻微上升（主要源于线程上下文开销）。Parquet 模式下整体内存占用极低（< 600MB）。
\end{itemize}

\subsection{数据格式对资源的影响 (Resource Impact by Format)}
图 \ref{fig:resource_comparison} 对比了在 24 线程下，处理 Parquet 与 CSV 时的资源开销差异。
\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/resource_format_comparison.png}
    \caption{Parquet vs CSV 资源开销对比 (Resource Usage by Format)}
    \label{fig:resource_comparison}
\end{figure}

\begin{itemize}
    \item \textbf{CPU 解析开销}: 尽管 CSV 性能较差，但其 CPU 利用率绝对值低于 Parquet，原因是 Parquet 执行效率高，能在短时间内充分利用 CPU；而 CSV 受限于内存分配和解析逻辑，导致 CPU 等待时间增加。
    \item \textbf{内存开销}: 两者差异显著。Parquet 模式下 Q1 仅需 \textbf{262 MB}，而 CSV 处理相同查询占用约 \textbf{2860 MB}。CSV 解析过程需创建大量临时对象，增加了内存分配器的压力。
\end{itemize}

\section{结论 (Conclusion)}
实验表明，DuckDB 在多核环境下表现出良好的并行扩展能力。同时，数据格式对性能影响显著：在分析场景下，采用 Parquet 相比 CSV 可获得明显的性能提升。推荐在生产环境中采用 Parquet 格式以优化性能。

\newpage
\appendix
\section{附录 (Appendix)}

\subsection{基准测试脚本 (benchmark.py)}
\lstinputlisting[language=Python, caption=benchmark.py]{benchmark.py}

\subsection{数据准备脚本 (prepare\_data.py)}
\lstinputlisting[language=Python, caption=prepare\_data.py]{prepare_data.py}

\subsection{实验结果数据 (Results)}
\lstinputlisting[language={}, caption=duckdb\_benchmark\_results.csv, basicstyle=\ttfamily\scriptsize]{duckdb_benchmark_results.csv}

\end{document}
